# This is the master LiteLLM configuration, generated from the agent taxonomy.
# It efficiently groups all required models by their provider.

model_list:
  - provider: "google"
    api_key: "env/GOOGLE_API_KEY"
    models:
      - "models/gemini-1.5-flash-latest"
      - "models/gemini-1.5-flash-8b-latest"
      - "models/gemma-3-12b-it"
      - "models/gemma-3-27b-it"
      - "google/gemma-3-1b-it"
      - "models/gemini-2.5-flash-preview-04-17-thinking"
      - "models/gemini-1.5-flash-002"

  - provider: "cohere"
    api_key: "env/COHERE_API_KEY"
    models:
      - "command-nightly"
      - "command-r"
      - "c4ai-aya-expanse-32b"
      - "c4ai-aya-vision-32b"
      - "command-r7b-12-2024"
      - "command-light-nightly"
      - "command-r-plus-08-2024"

  - provider: "groq"
    api_key: "env/GROQ_API_KEY"
    models:
      - "qwen/qwen3-32b"
      - "meta-llama/Llama-Guard-4-12B"
      - "meta-llama/llama-prompt-guard-2-22m"
      - "Llama3 70B (8192)"
      - "deepseek/deepseek-r1-distill-llama-70b"
      - "meta-llama/llama-4-maverick-17b-128e-instruct"
      - "llama-3.3-70b-versatile"
      - "gemma2-9b-it"
      - "compound-beta-mini"
      - "llama-3.1-8b-instant"
      - "allam-2-7b"
      - "qwen/qwq-32b"
      - "compound-beta"
      - "meta-llama/llama-4-scout-17b-16e-instruct"
      # The typo from the doc 'Llama3-ChatQA-1.5-8B' is likely a HF model, but placing here for completeness if a Groq version exists
      - "llama3-8b-8192"
      - "meta-llama/llama-prompt-guard-2-86m"
      
  - provider: "openrouter"
    api_key: "env/OPENROUTER_API_KEY"
    models:
      - "cognitivecomputations/dolphin3.0-mistral-24b:free"
      - "google/gemma-3-4b-it:free"
      - "microsoft/phi-4-reasoning-plus:free"
      - "nvidia/Llama-3.3-Nemotron-Super-49B-v1:free"
      - "shisa-ai/shisa-v2-llama3.3-70b:free"
      - "sarvamai/sarvam-m:free"
      - "deepseek/deepseek-r1-distill-qwen-32b:free"
      - "qwen/qwen3-235b-a22b:free"
      - "featherless/qwerky-72b:free"
      - "tngtech/deepseek-r1t-chimera:free"
      - "rekaai/reka-flash-3:free"
      - "moonshotai/kimi-vl-a3b-thinking:free"
      - "meta-llama/llama-4-maverick:free"
      - "mistralai/devstral-small:free"
      - "mistralai/mistral-small-3.1-24b-instruct:free"
      - "agentica-org/deepcoder-14b-preview:free"
      - "opengvlab/internvl3-14b:free"
      - "qwen/qwen2.5-vl-32b-instruct:free"
      - "qwen/qwen2.5-vl-72b-instruct:free"
      - "opengvlab/internvl3-2b:free"
      - "thudm/glm-z1-32b:free"
      - "deepseek/deepseek-r1-0528-qwen3-8b:free"
      - "Qwen/Qwen3-8B (free)"
      - "Qwen/Qwen3-14B (free)"
      - "Qwen/Qwen3-32B (free)"
      - "Qwen/Qwen3-30B-A3B (free)"
      - "qwen/qwq-32b:free"
      - "microsoft/mai-ds-r1:free"
      - "mistralai/mistral-small-24b-instruct-2501"
      - "mistralai/mistral-small-3.2-24b-instruct:free"
      - "moonshotai/kimi-dev-72b:free"
      - "nousresearch/deephermes-3-llama-3-8b-preview:free"
      - "deepseek/deepseek-v3-base:free"
      - "thudm/glm-4-32b:free"
      - "cognitivecomputations/dolphin3.0-r1-mistral-24b:free"
      - "deepseek/deepseek-chat-v3-0324:free"
      - "microsoft/phi-4-reasoning:free"
      - "arliai/qwq-32b-arliai-rpr-v1:free"

  - provider: "together_ai"
    api_key: "env/TOGETHER_API_KEY"
    models:
      - "meta-llama/Llama-3-8b-chat-hf"
      - "mistralai/Mistral-Small-24B-Instruct-2501"
      - "meta-llama/Llama-3.3-70B-Instruct-Turbo"
      - "arcee-ai/virtuoso-large"
      - "Salesforce/Llama-Rank-V1"
      - "meta-llama/Llama-3.1-Nemotron-70B-Instruct-HF"
      - "lgai/exaone-deep-32b"
      - "deepseek-ai/DeepSeek-V3"
      - "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo"
      - "Qwen/Qwen2.5-VL-72B-Instruct"
      - "meta-llama/Llama-Vision-Free"
      - "arcee-ai/AFM-4.5B-Preview"
      - "arcee-ai/arcee-blitz"
      - "arcee-ai/caller"
      - "google/gemma-2-27b-it"
      - "google/gemma-3n-E4B-it"
      - "meta-llama/Llama-3-8B-Instruct-Lite"
      - "Qwen/Qwen2.5-7B-Instruct-Turbo"
      - "marin-community/marin-8b-instruct"
      - "mistralai/Mistral-7B-Instruct-v0.1"
      - "mistralai/Mistral-7B-Instruct-v0.2"
      - "mistralai/Mistral-7B-Instruct-v0.3"
      - "scb10x/scb10x-typhoon-2-1-gemma3-12b"
      - "togethercomputer/Refuel-Llm-V2-Small"
      - "deepseek-ai/DeepSeek-R1"
      - "deepseek-ai/DeepSeek-R1-0528-tput"
      - "deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
      - "deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free"
      - "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
      - "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B"
      - "lgai/exaone-3-5-32b-instruct"
      - "meta-llama/Llama-2-70b-hf"
      - "meta-llama/Llama-3-70b-chat-hf"
      - "meta-llama/Llama-3.2-3B-Instruct-Turbo"
      - "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free"
      - "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8"
      - "meta-llama/Llama-4-Scout-17B-16E-Instruct"
      - "meta-llama/Meta-Llama-3-8B-Instruct-Lite"
      - "meta-llama/Meta-Llama-3-70B-Instruct-Turbo"
      - "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"
      - "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo"
      - "mistralai/Mixtral-8x7B-Instruct-v0.1"
      - "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO"
      - "Qwen/QwQ-32B"
      - "Qwen/Qwen2-72B-Instruct"
      - "Qwen/Qwen2.5-72B-Instruct-Turbo"
      - "Qwen/Qwen3-235B-A22B-fp8-tput"
      - "perplexity-ai/r1-1776"
      - "togethercomputer/Refuel-Llm-V2"
      - "scb10x/scb10x-llama3-1-typhoon2-70b-instruct"
      - "arcee-ai/virtuoso-medium-v2"
      - "arcee-ai/coder-large"
      - "arcee-ai/maestro-reasoning"
      - "arcee_ai/arcee-spotlight"
      - "deepseek-ai/DeepSeek-R1-0528-tput"
      - "meta-llama/Llama-Guard-3-11B-Vision-Turbo"
      - "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo"

  - provider: "huggingface"
    api_key: "env/HUGGINGFACE_TOKEN"
    models:
      - "THUDM/chatglm-6b"
      - "meta-llama/Llama-3.1-8B-Instruct"
      - "tiiuae/falcon-40b-instruct"
      - "databricks/dbrx-instruct"
      - "nvidia/Nemotron-4-340B-Instruct"
      - "tiiuae/falcon-180B-chat"
      - "mistralai/Mixtral-8x22B-Instruct-v0.1"
      - "mistralai/Mixtral-8x7B-Instruct-v0.1"
      - "2Noise/ChatTTS"
      - "ResembleAl/chatterbox"
      - "microsoft/Phi-3-vision-128k-instruct"
      - "Qwen/Qwen2-VL-72B-Instruct"
      - "timbrooks/instruct-pix2pix"
      - "microsoft/Phi-4-multimodal-instruct"
      - "microsoft/Phi-3.5-vision-instruct"
      - "mistralai/Mistral-Nemo-Instruct-2407"
      - "HuggingFaceTB/SmolLM2-1.7B-Instruct"
      - "gradientai/Llama-3-8B-Instruct-Gradient-1048k"
      - "shenzhi-wang/Llama3-8B-Chinese-Chat"
      - "Intel/neural-chat-7b-v3-1"
      - "intfloat/e5-mistral-7b-instruct"
      - "hkunlp/instructor-xl"
      - "deepseek-ai/DeepSeek-Coder-V2-Instruct"
      - "microsoft/Phi-3-mini-128k-instruct"
      - "meta-llama/Meta-Llama-3-70B-Instruct"
      - "THUDM/chatglm3-6b"
      - "Qwen/Qwen-7B-Chat"
      - "tencent/Hunyuan-A13B-Instruct"
      - "TheBloke/Llama-2-13B-chat-GGML"
      - "togethercomputer/GPT-NeoXT-Chat-Base-20B"
      - "THUDM/glm-4-9b-chat"
      - "baichuan-inc/Baichuan-13B-Chat"
      - "upstage/SOLAR-10.7B-Instruct-v1.0"
      - "TheBloke/Mistral-7B-Instruct-v0.1-GGUF"
      - "nvidia/Llama3-ChatQA-1.5-8B"
      - "microsoft/Phi-4-mini-instruct"
      - "mistralai/mistral-small-3.1-24b-instruct-2503"
      - "Qwen/Qwen2.5-7B-Instruct"
      - "TheBloke/Llama-2-7B-Chat-GGML"
      - "mistralai/Mistral-Large-Instruct-2407"
      - "meta-llama/Llama-3.1-70B-Instruct"
      - "TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF"
      - "meta-llama/Llama-2-7b-chat"
      - "nvidia/Llama-3.1-Nemotron-70B-Instruct"
      - "microsoft/Phi-3.5-MoE-instruct"
      - "meta-llama/Llama-3.2-1B-Instruct"
      - "tiiuae/falcon-7b-instruct"
      - "meta-llama/Llama-3.2-3B-Instruct"
      - "meta-llama/Llama-2-13b-chat-hf"
      - "Qwen/Qwen2.5-72B-Instruct"
      - "microsoft/Phi-3.5-mini-instruct"
      - "meta-llama/Llama-2-7b-chat-hf"
      - "mistralai/Mistral-7B-Instruct-v0.2"
      - "THUDM/chatglm2-6b"
      - "mistralai/Mistral-7B-Instruct-v0.3"
      - "mistralai/Mistral-7B-Instruct-v0.1"
      - "microsoft/Phi-3-mini-4k-instruct"
      - "meta-llama/Llama-3.3-70B-Instruct"
      - "Qwen/Qwen2.5-Coder-32B-Instruct"
      - "meta-llama/Llama-4-Scout-17B-16E-Instruct"
      - "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO"

  - provider: "cerebras"
    api_key: "env/CEREBRAS_API_KEY"
    models:
      - "Llama 4 Scout"
      - "Llama 3.3 70B"
      - "Llama 3.1 8B"
      
# General settings for LiteLLM
litellm_settings:
  set_verbose: True